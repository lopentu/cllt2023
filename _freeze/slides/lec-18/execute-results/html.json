{
  "hash": "598c33f06a7ea39490a0604f12363e13",
  "result": {
    "markdown": "---\ntitle: \"Logistic regression\"\nsubtitle: \"STA 210 - Spring 2022\"\nauthor: \"Dr. Mine Ã‡etinkaya-Rundel\"\nfooter: \"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)\"\nlogo: \"images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    transition: fade\n    slide-number: true\n    incremental: true \n    chalkboard: true\neditor: visual\nexecute:\n  freeze: auto\n  echo: true\n---\n\n\n\n# Welcome\n\n## Announcements\n\n-   Schedule changes for the remainder of the semester\n\n-   Thursday office hours in my office: 213 Old Chem\n\n-   Any questions on project proposals?\n\n## Topics\n\n-   Logistic regression for binary response variable\n\n-   Relationship between odds and probabilities\n\n-   Use logistic regression model to calculate predicted odds and probabilities\n\n## Computational setup\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(knitr)\nlibrary(Stat2Data)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))\n```\n:::\n\n# Predicting categorical outcomes\n\n## Types of outcome variables\n\n**Quantitative outcome variable**:\n\n-   Sales price of a house in Levittown, NY\n-   **Model**: Expected sales price given the number of bedrooms, lot size, etc.\n\n. . .\n\n**Categorical outcone variable**:\n\n-   High risk of coronary heart disease\n-   **Model**: Probability an adult is high risk of heart disease given their age, total cholesterol, etc.\n\n## Models for categorical outcomes\n\n::: columns\n::: {.column width=\"50%\"}\n**Logistic regression**\n\n2 Outcomes\n\n1: Yes, 0: No\n:::\n\n::: {.column width=\"50%\"}\n**Multinomial logistic regression**\n\n3+ Outcomes\n\n1: Democrat, 2: Republican, 3: Independent\n:::\n:::\n\n## 2020 election forecasts\n\n![](images/lec-18/fivethirtyeight_president_nc.png){fig-align=\"center\"}\n\nSource: [FiveThirtyEight Election Forcasts](https://projects.fivethirtyeight.com/2020-election-forecast/)\n\n## NBA finals predictions\n\n![](images/lec-18/nba-predictions.png){fig-align=\"center\"}\n\nSource: [FiveThirtyEight 2019-20 NBA Predictions](https://projects.fivethirtyeight.com/2020-nba-predictions/games/?ex_cid=rrpromo)\n\n## Do teenagers get 7+ hours of sleep? {.smaller}\n\n::: columns\n::: {.column width=\"40%\"}\nStudents in grades 9 - 12 surveyed about health risk behaviors including whether they usually get 7 or more hours of sleep.\n\n`Sleep7`\n\n1: yes\n\n0: no\n:::\n\n::: {.column width=\"60%\"}\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(YouthRisk2009)\nsleep <- YouthRisk2009 %>%\n  as_tibble() %>%\n  filter(!is.na(Age), !is.na(Sleep7))\nsleep %>%\n  relocate(Age, Sleep7)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 446 Ã— 6\n     Age Sleep7 Sleep           SmokeLife SmokeDaily MarijuaEver\n   <int>  <int> <fct>           <fct>     <fct>            <int>\n 1    16      1 8 hours         Yes       Yes                  1\n 2    17      0 5 hours         Yes       Yes                  1\n 3    18      0 5 hours         Yes       Yes                  1\n 4    17      1 7 hours         Yes       No                   1\n 5    15      0 4 or less hours No        No                   0\n 6    17      0 6 hours         No        No                   0\n 7    17      1 7 hours         No        No                   0\n 8    16      1 8 hours         Yes       No                   0\n 9    16      1 8 hours         No        No                   0\n10    18      0 4 or less hours Yes       Yes                  1\n# â€¦ with 436 more rows\n```\n:::\n:::\n:::\n:::\n\n## Plot the data\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(sleep, aes(x = Age, y = Sleep7)) +\n  geom_point() + \n  labs(y = \"Getting 7+ hours of sleep\")\n```\n\n::: {.cell-output-display}\n![](lec-18_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=90%}\n:::\n:::\n\n## Let's fit a linear regression model\n\n**Outcome:** $Y$ = 1: yes, 0: no\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-18_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=90%}\n:::\n:::\n\n## Let's use proportions\n\n**Outcome:** Probability of getting 7+ hours of sleep\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-18_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=90%}\n:::\n:::\n\n## What happens if we zoom out?\n\n**Outcome:** Probability of getting 7+ hours of sleep\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-18_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=90%}\n:::\n:::\n\nðŸ›‘ *This model produces predictions outside of 0 and 1.*\n\n## Let's try another model\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-18_files/figure-revealjs/logistic-model-plot-1.png){fig-align='center' width=90%}\n:::\n:::\n\n*âœ… This model (called a **logistic regression model**) only produces predictions between 0 and 1.*\n\n## The code\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(sleep_age, aes(x = Age, y = prop)) +\n  geom_point() + \n  geom_hline(yintercept = c(0,1), lty = 2) + \n  stat_smooth(method =\"glm\", method.args = list(family = \"binomial\"), \n              fullrange = TRUE, se = FALSE) +\n  labs(y = \"P(7+ hours of sleep)\") +\n  xlim(1, 40) +\n  ylim(-0.5, 1.5)\n```\n:::\n\n## Different types of models\n\n| Method                          | Outcome      | Model                                                     |\n|---------------------------------|--------------|-----------------------------------------------------------|\n| Linear regression               | Quantitative | $Y = \\beta_0 + \\beta_1~ X$                                |\n| Linear regression (transform Y) | Quantitative | $\\log(Y) = \\beta_0 + \\beta_1~ X$                          |\n| Logistic regression             | Binary       | $\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1 ~ X$ |\n\n# Odds and probabilities\n\n## Binary response variable\n\n-   $Y = 1: \\text{ yes}, 0: \\text{ no}$\n-   $\\pi$: **probability** that $Y=1$, i.e., $P(Y = 1)$\n-   $\\frac{\\pi}{1-\\pi}$: **odds** that $Y = 1$\n-   $\\log\\big(\\frac{\\pi}{1-\\pi}\\big)$: **log odds**\n-   Go from $\\pi$ to $\\log\\big(\\frac{\\pi}{1-\\pi}\\big)$ using the **logit transformation**\n\n## Odds\n\nSuppose there is a **70% chance** it will rain tomorrow\n\n-   Probability it will rain is $\\mathbf{p = 0.7}$\n-   Probability it won't rain is $\\mathbf{1 - p = 0.3}$\n-   Odds it will rain are **7 to 3**, **7:3**, $\\mathbf{\\frac{0.7}{0.3} \\approx 2.33}$\n\n## Are teenagers getting enough sleep?\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsleep %>%\n  count(Sleep7) %>%\n  mutate(p = round(n / sum(n), 3))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 2 Ã— 3\n  Sleep7     n     p\n   <int> <int> <dbl>\n1      0   150 0.336\n2      1   296 0.664\n```\n:::\n:::\n\n. . .\n\n$P(\\text{7+ hours of sleep}) = P(Y = 1) = p = 0.664$\n\n. . .\n\n$P(\\text{< 7 hours of sleep}) = P(Y = 0) = 1 - p = 0.336$\n\n. . .\n\n$P(\\text{odds of 7+ hours of sleep}) = \\frac{0.664}{0.336} = 1.976$\n\n## From odds to probabilities\n\n::: columns\n::: {.column width=\"50%\"}\n**odds**\n\n$$\\omega = \\frac{\\pi}{1-\\pi}$$\n:::\n\n::: {.column width=\"50%\"}\n**probability**\n\n$$\\pi = \\frac{\\omega}{1 + \\omega}$$\n:::\n:::\n\n## Logistic regression\n\n## From odds to probabilities\n\n(1) **Logistic model**: log odds = $\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~X$\n(2) **Odds =** $\\exp\\big\\{\\log\\big(\\frac{\\pi}{1-\\pi}\\big)\\big\\} = \\frac{\\pi}{1-\\pi}$\n(3) Combining (1) and (2) with what we saw earlier\n\n$$\\text{probability} = \\pi = \\frac{\\exp\\{\\beta_0 + \\beta_1~X\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X\\}}$$\n\n## Logistic regression model\n\n**Logit form**: $$\\log\\big(\\frac{\\pi}{1-\\pi}\\big) = \\beta_0 + \\beta_1~X$$\n\n. . .\n\n**Probability form**:\n\n$$\n\\pi = \\frac{\\exp\\{\\beta_0 + \\beta_1~X\\}}{1 + \\exp\\{\\beta_0 + \\beta_1~X\\}}\n$$\n\n## Risk of coronary heart disease\n\nThis dataset is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts.\nWe want to use `age` to predict if a randomly selected adult is high risk of having coronary heart disease in the next 10 years.\n\n`high_risk`:\n\n::: nonincremental\n-   1: High risk of having heart disease in next 10 years\n-   0: Not high risk of having heart disease in next 10 years\n:::\n\n`age`: Age at exam time (in years)\n\n## Data: `heart`\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheart_disease <- read_csv(here::here(\"slides\", \"data/framingham.csv\")) %>%\n  select(age, TenYearCHD) %>%\n  drop_na() %>%\n  mutate(high_risk = as.factor(TenYearCHD)) %>%\n  select(age, high_risk)\n\nheart_disease\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 2\n     age high_risk\n   <dbl> <fct>    \n 1    39 0        \n 2    46 0        \n 3    48 0        \n 4    61 1        \n 5    46 0        \n 6    43 0        \n 7    63 1        \n 8    45 0        \n 9    52 0        \n10    43 0        \n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n## High risk vs. age\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(heart_disease, aes(x = high_risk, y = age)) +\n  geom_boxplot() +\n  labs(x = \"High risk - 1: yes, 0: no\",\n       y = \"Age\", \n       title = \"Age vs. High risk of heart disease\")\n```\n\n::: {.cell-output-display}\n![](lec-18_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='center' width=90%}\n:::\n:::\n\n## Let's fit the model\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nheart_disease_fit <- logistic_reg() %>%\n  set_engine(\"glm\") %>%\n  fit(high_risk ~ age, data = heart_disease, family = \"binomial\")\n\ntidy(heart_disease_fit) %>% kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -5.561|     0.284|   -19.599|       0|\n|age         |    0.075|     0.005|    14.178|       0|\n:::\n:::\n\n## The model\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(heart_disease_fit) %>% kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   -5.561|     0.284|   -19.599|       0|\n|age         |    0.075|     0.005|    14.178|       0|\n:::\n:::\n\n. . .\\\n\\\n$$\\log\\Big(\\frac{\\hat{\\pi}}{1-\\hat{\\pi}}\\Big) = -5.561 + 0.075 \\times \\text{age}$$ where $\\hat{\\pi}$ is the predicted probability of being high risk\n\n## Predicted log odds\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\naugment(heart_disease_fit$fit)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 8\n   high_risk   age .fitted .resid .std.resid     .hat .sigma   .cooksd\n   <fct>     <dbl>   <dbl>  <dbl>      <dbl>    <dbl>  <dbl>     <dbl>\n 1 0            39  -2.65  -0.370     -0.370 0.000466  0.895 0.0000165\n 2 0            46  -2.13  -0.475     -0.475 0.000322  0.895 0.0000192\n 3 0            48  -1.98  -0.509     -0.509 0.000288  0.895 0.0000199\n 4 1            61  -1.01   1.62       1.62  0.000706  0.895 0.000968 \n 5 0            46  -2.13  -0.475     -0.475 0.000322  0.895 0.0000192\n 6 0            43  -2.35  -0.427     -0.427 0.000384  0.895 0.0000183\n 7 1            63  -0.858  1.56       1.56  0.000956  0.895 0.00113  \n 8 0            45  -2.20  -0.458     -0.458 0.000342  0.895 0.0000189\n 9 0            52  -1.68  -0.585     -0.585 0.000262  0.895 0.0000244\n10 0            43  -2.35  -0.427     -0.427 0.000384  0.895 0.0000183\n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n. . .\n\n**For observation 1**\n\n$$\\text{predicted odds} = \\hat{\\omega} = \\frac{\\hat{\\pi}}{1-\\hat{\\pi}} = \\exp\\{-2.650\\} = 0.071$$\n\n## Predicted probabilities\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, new_data = heart_disease, type = \"prob\")\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 2\n   .pred_0 .pred_1\n     <dbl>   <dbl>\n 1   0.934  0.0660\n 2   0.894  0.106 \n 3   0.878  0.122 \n 4   0.733  0.267 \n 5   0.894  0.106 \n 6   0.913  0.0870\n 7   0.702  0.298 \n 8   0.900  0.0996\n 9   0.843  0.157 \n10   0.913  0.0870\n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n. . .\n\n$$\\text{predicted probabilities} = \\hat{\\pi} = \\frac{\\exp\\{-2.650\\}}{1 + \\exp\\{-2.650\\}} = 0.066$$\n\n## Predicted classes\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, new_data = heart_disease, type = \"class\")\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 1\n   .pred_class\n   <fct>      \n 1 0          \n 2 0          \n 3 0          \n 4 0          \n 5 0          \n 6 0          \n 7 0          \n 8 0          \n 9 0          \n10 0          \n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n## Default prediction\n\nFor a logistic regression, the default prediction is the `class`.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, new_data = heart_disease)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 4,240 Ã— 1\n   .pred_class\n   <fct>      \n 1 0          \n 2 0          \n 3 0          \n 4 0          \n 5 0          \n 6 0          \n 7 0          \n 8 0          \n 9 0          \n10 0          \n# â€¦ with 4,230 more rows\n```\n:::\n:::\n\n## Observed vs. predicted\n\n::: question\nWhat does the following table show?\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(heart_disease_fit, new_data = heart_disease) %>%\n  bind_cols(heart_disease) %>%\n  count(high_risk, .pred_class)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 2 Ã— 3\n  high_risk .pred_class     n\n  <fct>     <fct>       <int>\n1 0         0            3596\n2 1         0             644\n```\n:::\n:::\n\n## Recap\n\n-   Logistic regression for binary response variable\n\n-   Relationship between odds and probabilities\n\n-   Used logistic regression model to calculate predicted odds and probabilities\n\n## Application exercise\n\n::: appex\nðŸ“‹ [github.com/sta210-s22/ae-9-odds](https://github.com/sta210-s22/ae-9-odds)\n:::",
    "supporting": [
      "lec-18_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}