{
  "hash": "b5d3438e219cb4164eaf9edd5bebc45f",
  "result": {
    "markdown": "---\ntitle: \"SLR: Prediction + model evaluation\"\nsubtitle: \"STA 210 - Spring 2022\"\nauthor: \"Dr. Mine Çetinkaya-Rundel\"\nfooter:  \"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)\"\nlogo: \"images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    multiplex: true\n    transition: fade\n    slide-number: true\n    incremental: true \neditor: visual\nexecute:\n  freeze: auto\n---\n\n\n\n# Welcome\n\n## Announcements\n\n-   New on the course website: [FAQ](/course-faq.html)\n-   New communication tool: Slack\n    -   Find the invite link in your inbox / on Sakai announcements\n    -   Use #general for questions, #random for random 🤪\n    -   Use code formatting for for questions involving code (see Course FAQ for a demo video)\n-   My office hours: All virtual for now, hope to move 1 hour / week to in person later in the semester\n\n## Hybrid teaching {.smaller}\n\n-   Lectures:\n    -   In person as long as university says so (and I don't have COVID)\n    -   If you can't be in class (and you're well enough to follow along), watch live (or the recording later) on [Panopto](https://duke.hosted.panopto.com/Panopto/Pages/Sessions/List.aspx#folderID=%22d6c1d58a-cb6d-4732-9d4b-ae0c011bf767%22)\n    -   Watching live and have questions? Post on Slack!\n    -   In class and see someone ask a question on Slack? Please raise it to me!\n-   Labs:\n    -   Not live streamed / recorded\n    -   Lab 2 (next Monday) - individual\n    -   Lab 3 onwards - in teams, if teammates are in isolation, set up team Zoom calls\n\n## Computational setup\n\n::: {.cell}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)   # for data wrangling and visualization\nlibrary(tidymodels)  # for modeling\nlibrary(usdata)      # for the county_2019 dataset\nlibrary(scales)      # for pretty axis labels\nlibrary(glue)        # for constructing character strings\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n```\n:::\n\n# Application exercise\n\n::: appex\n📋 [github.com/sta210-s22/ae-2-dcbikeshare](https://github.com/sta210-s22/?q=ae-2-dcbikeshare&type=all&language=&sort=)\n:::\n\n# Uninsurance and high school graduation rates in NC\n\n## Data source\n\n-   The data come from [`usdata::county_2019`](https://openintrostat.github.io/usdata/reference/county_2019.html)\n-   These data have been compiled from the 2019 American Community Survey\n\n::: {.cell}\n\n:::\n\n## Uninsurance rate\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-1-1.png){width=100%}\n:::\n:::\n\n## High school graduation rate\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-2-1.png){width=100%}\n:::\n:::\n\n## Examining the relationship\n\n-   The [NC Labor and Economic Analysis Division (LEAD)](https://www.nc.gov/agency/labor-and-economic-analysis-division), which \"administers and collects data, conducts research, and publishes information on the state's economy, labor force, educational, and workforce-related issues\".\n-   Suppose that an analyst working for LEAD is interested in the relationship between uninsurance and high school graduation rates in NC counties.\n\n. . .\n\n::: question\nWhat type of visualization should the analyst make to examine the relationship between these two variables?\n:::\n\n## Data prep\n\n::: {.cell}\n\n```{.r .cell-code}\ncounty_2019_nc <- county_2019 %>%\n  as_tibble() %>%\n  filter(state == \"North Carolina\") %>%\n  select(name, hs_grad, uninsured)\n\ncounty_2019_nc\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 100 × 3\n   name             hs_grad uninsured\n   <chr>              <dbl>     <dbl>\n 1 Alamance County     86.3      11.2\n 2 Alexander County    82.4       8.9\n 3 Alleghany County    77.5      11.3\n 4 Anson County        80.7      11.1\n 5 Ashe County         85.1      12.6\n 6 Avery County        83.6      15.9\n 7 Beaufort County     87.7      12  \n 8 Bertie County       78.4      11.9\n 9 Bladen County       81.3      12.9\n10 Brunswick County    91.3       9.8\n# … with 90 more rows\n```\n:::\n:::\n\n## Uninsurance vs. HS graduation rates\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(county_2019_nc,\n       aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  ) +\n  geom_point(data = county_2019_nc %>% filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured), shape = \"circle open\", color = \"#8F2D56\", size = 4, stroke = 2) +\n  geom_text(data = county_2019_nc %>% filter(name == \"Durham County\"), aes(x = hs_grad, y = uninsured, label = name), color = \"#8F2D56\", fontface = \"bold\", nudge_y = 3, nudge_x = 2)\n```\n\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/nc-uninsured-hsgrad-scatter-1.png){width=80%}\n:::\n:::\n\n## Modeling the relationship\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(county_2019_nc, aes(x = hs_grad, y = uninsured)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"#8F2D56\") +\n  scale_x_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  scale_y_continuous(labels = label_percent(scale = 1, accuracy = 1)) +\n  labs(\n    x = \"High school graduate\", y = \"Uninsured\",\n    title = \"Uninsurance vs. HS graduation rates\",\n    subtitle = \"North Carolina counties, 2015 - 2019\"\n  )\n```\n\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/nc-uninsured-hsgrad-scatter-line-1.png){width=80%}\n:::\n:::\n\n## Fitting the model\n\nWith `fit()`:\n\n::: {.cell}\n\n```{.r .cell-code}\nnc_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(uninsured ~ hs_grad, data = county_2019_nc)\n\ntidy(nc_fit)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)   33.9      3.99        8.50 2.12e-13\n2 hs_grad       -0.262    0.0468     -5.61 1.88e- 7\n```\n:::\n:::\n\n## Augmenting the data\n\nWith `augment()` to add columns for predicted values (`.fitted`), residuals (`.resid`), etc.:\n\n::: {.cell}\n\n```{.r .cell-code}\nnc_aug <- augment(nc_fit$fit)\nnc_aug\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 100 × 8\n   uninsured hs_grad .fitted  .resid   .hat .sigma    .cooksd .std.resid\n       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>      <dbl>      <dbl>\n 1      11.2    86.3   11.3  -0.0633 0.0107   2.10 0.00000501    -0.0305\n 2       8.9    82.4   12.3  -3.39   0.0138   2.07 0.0186        -1.63  \n 3      11.3    77.5   13.6  -2.27   0.0393   2.09 0.0252        -1.11  \n 4      11.1    80.7   12.7  -1.63   0.0199   2.09 0.00633       -0.790 \n 5      12.6    85.1   11.6   1.02   0.0100   2.10 0.00122        0.492 \n 6      15.9    83.6   12.0   3.93   0.0112   2.06 0.0203         1.89  \n 7      12      87.7   10.9   1.10   0.0133   2.10 0.00191        0.532 \n 8      11.9    78.4   13.3  -1.44   0.0328   2.09 0.00830       -0.700 \n 9      12.9    81.3   12.6   0.324  0.0174   2.10 0.000218       0.157 \n10       9.8    91.3    9.95 -0.151  0.0291   2.10 0.0000806     -0.0734\n# … with 90 more rows\n```\n:::\n:::\n\n## Visualizing the model I {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   **Black circles:** Observed values (`y = uninsured`)\n:::\n:::\n\n::: {.column width=\"75%\"}\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-6-1.png){width=100%}\n:::\n:::\n:::\n:::\n\n## Visualizing the model II {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Black circles: Observed values (`y = uninsured`)\n-   **Pink solid line:** Least squares regression line\n:::\n:::\n\n::: {.column width=\"75%\"}\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-7-1.png){width=100%}\n:::\n:::\n:::\n:::\n\n## Visualizing the model III {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Black circles: Observed values (`y = uninsured`)\n-   Pink solid line: Least squares regression line\n-   **Maroon triangles:** Predicted values (`y = .fitted`)\n:::\n:::\n\n::: {.column width=\"75%\"}\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-8-1.png){width=100%}\n:::\n:::\n:::\n:::\n\n## Visualizing the model IV {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Black circles: Observed values (`y = uninsured`)\n-   Pink solid line: Least squares regression line\n-   Maroon triangles: Predicted values (`y = .fitted`)\n-   **Gray dashed lines:** Residuals\n:::\n:::\n\n::: {.column width=\"75%\"}\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-9-1.png){width=100%}\n:::\n:::\n:::\n:::\n\n## Evaluating the model fit\n\n::: question\nHow can we evaluate whether the model for predicting uninsurance rate from high school graduation rate for NC counties is a good fit?\n:::\n\n# Model evaluation\n\n## Two statistics {.smaller}\n\n-   **R-squared**, $R^2$ : Percentage of variability in the outcome explained by the regression model (in the context of SLR, the predictor)\n\n    $$\n    R^2 = Cor(x,y)^2 = Cor(y, \\hat{y})^2\n    $$\n\n-   **Root mean square error, RMSE**: A measure of the average error (average difference between observed and predicted values of the outcome)\n\n    $$\n    RMSE = \\sqrt{\\frac{\\sum_{i = 1}^n (y_i - \\hat{y}_i)^2}{n}}\n    $$\n\n. . .\n\n::: question\nWhat indicates a good model fit?\nHigher or lower $R^2$?\nHigher or lower RMSE?\n:::\n\n## R-squared {.smaller}\n\n-   Ranges between 0 (terrible predictor) and 1 (perfect predictor)\n\n-   Unitless\n\n-   Calculate with `rsq()`:\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    rsq(nc_aug, truth = uninsured, estimate = .fitted)\n    ```\n    \n    ::: {.cell-output-stdout}\n    ```\n    # A tibble: 1 × 3\n      .metric .estimator .estimate\n      <chr>   <chr>          <dbl>\n    1 rsq     standard       0.243\n    ```\n    :::\n    :::\n\n## Interpreting R-squared {.smaller}\n\n::: {.cell}\n\n:::\n\n::: poll\n🗳️ **Vote on Slack**\n\nThe $R^2$ of the model for predicting uninsurance rate from high school graduation rate for NC counties is 24.3%.\nWhich of the following is the correct interpretation of this value?\n\n::: nonincremental\n-   High school graduation rates correctly predict 24.3% of uninsurance rates in NC counties.\n-   24.3% of the variability in uninsurance rates in NC counties can be explained by high school graduation rates.\n-   24.3% of the variability in high school graduation rates in NC counties can be explained by uninsurance rates.\n-   24.3% of the time uninsurance rates in NC counties can be predicted by high school graduation rates.\n:::\n:::\n\n## Alternative approach for R-squared\n\nAlternatively, use `glance()` to construct a single row summary of the model fit, including $R^2$:\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(nc_fit)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.243         0.235  2.09      31.5 0.000000188     1  -214.  435.  443.\n# … with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n\n```{.r .cell-code}\nglance(nc_fit)$r.squared\n```\n\n::: {.cell-output-stdout}\n```\n[1] 0.2430694\n```\n:::\n:::\n\n## RMSE\n\n-   Ranges between 0 (perfect predictor) and infinity (terrible predictor)\n\n-   Same units as the outcome variable\n\n-   Calculate with `rmse()`:\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    rmse(nc_aug, truth = uninsured, estimate = .fitted)\n    ```\n    \n    ::: {.cell-output-stdout}\n    ```\n    # A tibble: 1 × 3\n      .metric .estimator .estimate\n      <chr>   <chr>          <dbl>\n    1 rmse    standard        2.07\n    ```\n    :::\n    :::\n\n-   The value of RMSE is not very meaningful on its own, but it's useful for comparing across models (more on this when we get to regression with multiple predictors)\n\n## Obtaining R-squared and RMSE {.smaller}\n\n-   Use `rsq()` and `rmse()`, respectively\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    rsq(nc_aug, truth = uninsured, estimate = .fitted)\n    rmse(nc_aug, truth = uninsured, estimate = .fitted)\n    ```\n    :::\n\n-   First argument: data frame containing `truth` and `estimate` columns\n\n-   Second argument: name of the column containing `truth` (observed outcome)\n\n-   Third argument: name of the column containing `estimate` (predicted outcome)\n\n## Purpose of model evaluation\n\n-   $R^2$ tells us how our model is doing to predict the data we *already have*\n-   But generally we are interested in prediction for a new observation, not for one that is already in our sample, i.e. **out-of-sample prediction**\n-   We have a couple ways of *simulating* out-of-sample prediction before actually getting new data to evaluate the performance of our models\n\n# Splitting data\n\n## Spending our data\n\n-   There are several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.\n-   Doing all of this on the entire data we have available leaves us with no other data to assess our choices\n-   We can allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we've done so far)\n\n## Simulation: data splitting {.smaller}\n\n::: columns\n::: {.column width=\"30%\"}\n::: nonincremental\n-   Take a random sample of 10% of the data and set aside (testing data)\n-   Fit a model on the remaining 90% of the data (training data)\n-   Use the coefficients from this model to make predictions for the testing data\n-   Repeat 10 times\n:::\n:::\n\n::: {.column width=\"70%\"}\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-15-1.png){width=100%}\n:::\n:::\n:::\n:::\n\n## Predictive performance {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: question\n::: nonincremental\n-   How consistent are the predictions for different testing datasets?\n-   How consistent are the predictions for counties with high school graduation rates in the middle of the plot vs. in the edges?\n:::\n:::\n:::\n\n::: {.column width=\"75%\"}\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-16-1.png){width=100%}\n:::\n:::\n:::\n:::\n\n# Bootstrapping\n\n## Bootstrapping our data {.smaller}\n\n-   The idea behind bootstrapping is that if a given observation exists in a sample, there may be more like it in the population\n-   With bootstrapping, we simulate resampling from the population by resampling from the sample we observed\n-   Bootstrap samples are the sampled *with replacement* from the original sample and same size as the original sample\n    -   For example, if our sample consists of the observations {A, B, C}, bootstrap samples could be {A, A, B}, {A, C, A}, {B, C, C}, {A, B, C}, etc.\n\n## Simulation: bootstrapping {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: nonincremental\n-   Take a bootstrap sample -- sample with replacement from the original data, same size as the original data\n-   Fit model to the sample and make predictions for that sample\n-   Repeat many times\n:::\n:::\n\n::: {.column width=\"75%\"}\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-17-1.png){width=100%}\n:::\n:::\n:::\n:::\n\n## Predictive performance {.smaller}\n\n::: columns\n::: {.column width=\"25%\"}\n::: question\n::: nonincremental\n-   How consistent are the predictions for different bootstrap datasets?\n-   How consistent are the predictions for counties with high school graduation rates in the middle of the plot vs. in the edges?\n:::\n:::\n:::\n\n::: {.column width=\"75%\"}\n::: {.cell}\n::: {.cell-output-display}\n![](lec-4_files/figure-revealjs/unnamed-chunk-18-1.png){width=100%}\n:::\n:::\n:::\n:::",
    "supporting": [
      "lec-4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}