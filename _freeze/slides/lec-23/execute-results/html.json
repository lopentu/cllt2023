{
  "hash": "d84688896c21ee7ec0c42069a120455c",
  "result": {
    "markdown": "---\ntitle: \"Multinomial Logistic Regression (MultiLR)\"\nsubtitle: \"STA 210 - Spring 2022\"\nauthor: \"Dr. Mine Çetinkaya-Rundel\"\nfooter: \"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)\"\nlogo: \"images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    transition: fade\n    slide-number: true\n    incremental: true \n    chalkboard: true\neditor: visual\nexecute:\n  freeze: auto\n  echo: true\n---\n\n\n\n# Welcome\n\n## Topics\n\n::: nonincremental\n-   Introduce multinomial logistic regression\n\n-   Interpret model coefficients\n\n-   Inference for a coefficient $\\beta_{jk}$\n:::\n\n## Computational setup\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(NHANES)\nlibrary(knitr)\nlibrary(patchwork)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))\n```\n:::\n\n# Generalized Linear Models\n\n## Generalized Linear Models (GLMs) {.smaller}\n\n-   In practice, there are many different types of outcome variables:\n\n    ::: nonincremental\n    -   **Binary**: Win or Lose\n    -   **Nominal**: Democrat, Republican or Third Party candidate\n    -   **Ordered**: Movie rating (1 - 5 stars)\n    -   and others...\n    :::\n\n-   Predicting each of these outcomes requires a **generalized linear model**, a broader class of models that *generalize* the multiple linear regression model\n\n::: callout-note\nRecommended reading for more details about GLMs: [*Generalized Linear Models: A Unifying Theory*](https://bookdown.org/roback/bookdown-bysh/ch-glms.html).\n:::\n\n## Binary outcome (Logistic)\n\n-   Given $P(y_i=1|x_i)= \\hat{\\pi}_i\\hspace{5mm} \\text{ and } \\hspace{5mm}P(y_i=0|x_i) = 1-\\hat{\\pi}_i$\n\n    $$\n    \\log\\Big(\\frac{\\hat{\\pi}_i}{1-\\hat{\\pi}_i}\\Big) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i}\n    $$\n\n-   We can calculate $\\hat{\\pi}_i$ by solving the logit equation:\n\n    $$\n    \\hat{\\pi}_i = \\frac{e^{\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i}}}{1 + e^{\\hat{\\beta}_0 + \\hat{\\beta}_1 x_{i}}}\n    $$\n\n## Binary outcome (Logistic) {.smaller}\n\n-   Suppose we consider $y=0$ the **baseline category** such that\n\n    $$\n    P(y_i=1|x_i) = \\hat{\\pi}_{i1} \\hspace{2mm}  \\text{ and } \\hspace{2mm} P(y_i=0|x_i) = \\hat{\\pi}_{i0}\n    $$\n\n-   Then the logistic regression model is\n\n    $$\n    \\log\\bigg(\\frac{\\hat{\\pi}_{i1}}{1- \\hat{\\pi}_{i1}}\\bigg) = \\log\\bigg(\\frac{\\hat{\\pi}_{i1}}{\\hat{\\pi}_{i0}}\\bigg) = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i\n    $$\n\n-   Slope, $\\hat{\\beta}_1$: When $x$ increases by one unit, the odds of $y=1$ versus the baseline $y=0$ are expected to multiply by a factor of $e^{\\hat{\\beta}_1}$\n\n-   Intercept, $\\hat{\\beta}_0$: When $x=0$, the predicted odds of $y=1$ versus the baseline $y=0$ are $\\exp\\{\\hat{\\beta}_0\\}$\n\n## Multinomial outcome variable\n\n-   Suppose the outcome variable $y$ is categorical and can take values $1, 2, \\ldots, K$ such that $(K > 2)$\n\n-   **Multinomial Distribution:**\n\n    $$\n    P(y=1) = \\pi_1, P(y=2) = \\pi_2, \\ldots, P(y=K) = \\pi_K\n    $$\n\n    such that $\\sum\\limits_{k=1}^{K} \\pi_k = 1$\n\n## Multinomial Logistic Regression {.smaller}\n\n-   If we have an explanatory variable $x$, then we want to fit a model such that $P(y = k) = \\pi_k$ is a function of $x$\n\n-   Choose a baseline category.\n    Let's choose $y=1$.\n    Then,\n\n    $$\n    \\log\\bigg(\\frac{\\pi_{ik}}{\\pi_{i1}}\\bigg) = \\beta_{0k} + \\beta_{1k} x_i\n    $$\n\n-   In the multinomial logistic model, we have a separate equation for each category of the outcome relative to the baseline category\n\n    -   If the outcome has $K$ possible categories, there will be $K-1$ equations as part of the multinomial logistic model\n\n## Multinomial Logistic Regression\n\n-   Suppose we have a outcome variable $y$ that can take three possible outcomes that are coded as \"A\", \"B\", \"C\"\n\n-   Let \"A\" be the baseline category.\n    Then\n\n    $$\n    \\log\\bigg(\\frac{\\pi_{iB}}{\\pi_{iA}}\\bigg) = \\beta_{0B} + \\beta_{1B}x_i \\\\[10pt]\n    \\log\\bigg(\\frac{\\pi_{iC}}{\\pi_{iA}}\\bigg) = \\beta_{0C} + \\beta_{1C} x_i\n    $$\n\n# Data\n\n## NHANES Data\n\n-   [National Health and Nutrition Examination Survey](https://www.cdc.gov/nchs/nhanes/index.htm) is conducted by the National Center for Health Statistics (NCHS)\n\n-   The goal is to *\"assess the health and nutritional status of adults and children in the United States\"*\n\n-   This survey includes an interview and a physical examination\n\n## NHANES Data\n\n-   We will use the data from the `NHANES` R package\n\n-   Contains 75 variables for the 2009 - 2010 and 2011 - 2012 sample years\n\n-   The data in this package is modified for educational purposes and should **not** be used for research\n\n-   Original data can be obtained from the [NCHS website](https://www.cdc.gov/nchs/data_access/index.htm) for research purposes\n\n-   Type `?NHANES` in console to see list of variables and definitions\n\n## Variables\n\n**Goal:** Use a person's age and whether they do regular physical activity to predict their self-reported health rating.\n\n-   Outcome: `HealthGen`: Self-reported rating of participant's health in general.\n    Excellent, Vgood, Good, Fair, or Poor.\n\n-   Predictors:\n\n    -   `Age`:Age at time of screening (in years). Participants 80 or older were recorded as 80.\n    -   `PhysActive`: Participant does moderate to vigorous-intensity sports, fitness or recreational activities.\n\n## The data\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnhanes_adult <- NHANES %>%\n  filter(Age >= 18) %>%\n  select(HealthGen, Age, PhysActive) %>%\n  drop_na() %>%\n  mutate(obs_num = 1:n())\n```\n:::\n\n. . .\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(nhanes_adult)\n```\n\n::: {.cell-output-stdout}\n```\nRows: 6,710\nColumns: 4\n$ HealthGen  <fct> Good, Good, Good, Good, Vgood, Vgood, Vgood, Vgood, Vgood, …\n$ Age        <int> 34, 34, 34, 49, 45, 45, 45, 66, 58, 54, 50, 33, 60, 56, 56,…\n$ PhysActive <fct> No, No, No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, …\n$ obs_num    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n```\n:::\n:::\n\n## Exploratory data analysis\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-23_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=80%}\n:::\n:::\n\n## Exploratory data analysis\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-23_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=80%}\n:::\n:::\n\n# Fitting a multinomial logistic regression\n\n## Model in R\n\nUse the `multinom_reg()` function with the `\"nnet\"` engine:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhealth_fit <- multinom_reg() %>%\n  set_engine(\"nnet\") %>%\n  fit(HealthGen ~ Age + PhysActive, data = nhanes_adult)\n```\n:::\n\n## Model result\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhealth_fit\n```\n\n::: {.cell-output-stdout}\n```\nparsnip model object\n\nFit time:  113ms \nCall:\nnnet::multinom(formula = HealthGen ~ Age + PhysActive, data = data, \n    trace = FALSE)\n\nCoefficients:\n      (Intercept)           Age PhysActiveYes\nVgood   1.2053460  0.0009101848    -0.3209047\nGood    1.9476261 -0.0023686122    -1.0014925\nFair    0.9145492  0.0030462534    -1.6454297\nPoor   -1.5211414  0.0221905681    -2.6556343\n\nResidual Deviance: 17588.88 \nAIC: 17612.88 \n```\n:::\n:::\n\n## Next steps\n\n::: question\nWhat function do we use to get the model summary, i.e., coefficient estimates.\n:::\n\n. . .\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(health_fit)\n```\n\n::: {.cell-output-error}\n```\nError in model.frame.default(formula = HealthGen ~ Age + PhysActive, data = data): 'data' must be a data.frame, environment, or list\n```\n:::\n:::\n\n## Looking inside the result of `fit()`\n\n::: question\nWhat is the name of the dataset in the call?\nIs it right?\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhealth_fit$fit$call\n```\n\n::: {.cell-output-stdout}\n```\nnnet::multinom(formula = HealthGen ~ Age + PhysActive, data = data, \n    trace = FALSE)\n```\n:::\n:::\n\n## Repair, and get back on track\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhealth_fit <- repair_call(health_fit, data = nhanes_adult)\nhealth_fit$fit$call\n```\n\n::: {.cell-output-stdout}\n```\nnnet::multinom(formula = HealthGen ~ Age + PhysActive, data = nhanes_adult, \n    trace = FALSE)\n```\n:::\n\n```{.r .cell-code}\ntidy(health_fit)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 12 × 6\n   y.level term           estimate std.error statistic  p.value\n   <chr>   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n 1 Vgood   (Intercept)    1.21       0.145       8.33  8.42e-17\n 2 Vgood   Age            0.000910   0.00246     0.369 7.12e- 1\n 3 Vgood   PhysActiveYes -0.321      0.0929     -3.45  5.51e- 4\n 4 Good    (Intercept)    1.95       0.141      13.8   1.39e-43\n 5 Good    Age           -0.00237    0.00242    -0.977 3.29e- 1\n 6 Good    PhysActiveYes -1.00       0.0901    -11.1   1.00e-28\n 7 Fair    (Intercept)    0.915      0.164       5.57  2.61e- 8\n 8 Fair    Age            0.00305    0.00288     1.06  2.90e- 1\n 9 Fair    PhysActiveYes -1.65       0.107     -15.3   5.69e-53\n10 Poor    (Intercept)   -1.52       0.290      -5.24  1.62e- 7\n11 Poor    Age            0.0222     0.00491     4.52  6.11e- 6\n12 Poor    PhysActiveYes -2.66       0.236     -11.3   1.75e-29\n```\n:::\n:::\n\n## Model output\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(health_fit)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 12 × 6\n   y.level term           estimate std.error statistic  p.value\n   <chr>   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n 1 Vgood   (Intercept)    1.21       0.145       8.33  8.42e-17\n 2 Vgood   Age            0.000910   0.00246     0.369 7.12e- 1\n 3 Vgood   PhysActiveYes -0.321      0.0929     -3.45  5.51e- 4\n 4 Good    (Intercept)    1.95       0.141      13.8   1.39e-43\n 5 Good    Age           -0.00237    0.00242    -0.977 3.29e- 1\n 6 Good    PhysActiveYes -1.00       0.0901    -11.1   1.00e-28\n 7 Fair    (Intercept)    0.915      0.164       5.57  2.61e- 8\n 8 Fair    Age            0.00305    0.00288     1.06  2.90e- 1\n 9 Fair    PhysActiveYes -1.65       0.107     -15.3   5.69e-53\n10 Poor    (Intercept)   -1.52       0.290      -5.24  1.62e- 7\n11 Poor    Age            0.0222     0.00491     4.52  6.11e- 6\n12 Poor    PhysActiveYes -2.66       0.236     -11.3   1.75e-29\n```\n:::\n:::\n\n## Model output, with CI\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(health_fit, conf.int = TRUE)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 12 × 8\n   y.level term         estimate std.error statistic  p.value conf.low conf.high\n   <chr>   <chr>           <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1 Vgood   (Intercept)   1.21e+0   0.145       8.33  8.42e-17  0.922     1.49   \n 2 Vgood   Age           9.10e-4   0.00246     0.369 7.12e- 1 -0.00392   0.00574\n 3 Vgood   PhysActiveY… -3.21e-1   0.0929     -3.45  5.51e- 4 -0.503    -0.139  \n 4 Good    (Intercept)   1.95e+0   0.141      13.8   1.39e-43  1.67      2.22   \n 5 Good    Age          -2.37e-3   0.00242    -0.977 3.29e- 1 -0.00712   0.00238\n 6 Good    PhysActiveY… -1.00e+0   0.0901    -11.1   1.00e-28 -1.18     -0.825  \n 7 Fair    (Intercept)   9.15e-1   0.164       5.57  2.61e- 8  0.592     1.24   \n 8 Fair    Age           3.05e-3   0.00288     1.06  2.90e- 1 -0.00260   0.00869\n 9 Fair    PhysActiveY… -1.65e+0   0.107     -15.3   5.69e-53 -1.86     -1.43   \n10 Poor    (Intercept)  -1.52e+0   0.290      -5.24  1.62e- 7 -2.09     -0.952  \n11 Poor    Age           2.22e-2   0.00491     4.52  6.11e- 6  0.0126    0.0318 \n12 Poor    PhysActiveY… -2.66e+0   0.236     -11.3   1.75e-29 -3.12     -2.19   \n```\n:::\n:::\n\n## Model output, with CI {.smaller}\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n|y.level |term          | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-------|:-------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|Vgood   |(Intercept)   |    1.205|     0.145|     8.325|   0.000|    0.922|     1.489|\n|Vgood   |Age           |    0.001|     0.002|     0.369|   0.712|   -0.004|     0.006|\n|Vgood   |PhysActiveYes |   -0.321|     0.093|    -3.454|   0.001|   -0.503|    -0.139|\n|Good    |(Intercept)   |    1.948|     0.141|    13.844|   0.000|    1.672|     2.223|\n|Good    |Age           |   -0.002|     0.002|    -0.977|   0.329|   -0.007|     0.002|\n|Good    |PhysActiveYes |   -1.001|     0.090|   -11.120|   0.000|   -1.178|    -0.825|\n|Fair    |(Intercept)   |    0.915|     0.164|     5.566|   0.000|    0.592|     1.237|\n|Fair    |Age           |    0.003|     0.003|     1.058|   0.290|   -0.003|     0.009|\n|Fair    |PhysActiveYes |   -1.645|     0.107|   -15.319|   0.000|   -1.856|    -1.435|\n|Poor    |(Intercept)   |   -1.521|     0.290|    -5.238|   0.000|   -2.090|    -0.952|\n|Poor    |Age           |    0.022|     0.005|     4.522|   0.000|    0.013|     0.032|\n|Poor    |PhysActiveYes |   -2.656|     0.236|   -11.275|   0.000|   -3.117|    -2.194|\n:::\n:::\n\n## Fair vs. Excellent Health\n\nThe baseline category for the model is `Excellent`.\n\n. . .\n\nThe model equation for the log-odds a person rates themselves as having \"Fair\" health vs. \"Excellent\" is\n\n$$\n\\log\\Big(\\frac{\\hat{\\pi}_{Fair}}{\\hat{\\pi}_{Excellent}}\\Big) = 0.915  + 0.003 ~ \\text{age} - 1.645 ~ \\text{PhysActive}\n$$\n\n## Interpretations {.smaller}\n\n$$\n\\log\\Big(\\frac{\\hat{\\pi}_{Fair}}{\\hat{\\pi}_{Excellent}}\\Big) = 0.915  + 0.003 ~ \\text{age} - 1.645 ~ \\text{PhysActive}\n$$\n\nFor each additional year in age, the odds a person rates themselves as having fair health versus excellent health are expected to multiply by 1.003 (exp(0.003)), holding physical activity constant.\n\n. . .\n\nThe odds a person who does physical activity will rate themselves as having fair health versus excellent health are expected to be 0.193 (exp(-1.645)) times the odds for a person who doesn't do physical activity, holding age constant.\n\n## Interpretations\n\n$$\n\\log\\Big(\\frac{\\hat{\\pi}_{Fair}}{\\hat{\\pi}_{Excellent}}\\Big) = 0.915  + 0.003 ~ \\text{age} - 1.645 ~ \\text{PhysActive}\n$$\n\nThe odds a 0 year old person who doesn't do physical activity rates themselves as having fair health vs. excellent health are 2.497 (exp(0.915)).\n\n. . .\n\n⚠️ **Need to mean-center age for the intercept to have a meaningful interpretation!**\n\n## Hypothesis test for $\\beta_{jk}$\n\nThe test of significance for the coefficient $\\beta_{jk}$ is\n\n**Hypotheses**: $H_0: \\beta_{jk} = 0 \\hspace{2mm} \\text{ vs } \\hspace{2mm} H_a: \\beta_{jk} \\neq 0$\n\n**Test Statistic**: $$z = \\frac{\\hat{\\beta}_{jk} - 0}{SE(\\hat{\\beta_{jk}})}$$\n\n**P-value**: $P(|Z| > |z|)$,\n\nwhere $Z \\sim N(0, 1)$, the Standard Normal distribution\n\n## Confidence interval for $\\beta_{jk}$\n\n-   We can calculate the **C% confidence interval** for $\\beta_{jk}$ using $\\hat{\\beta}_{jk} \\pm z^* SE(\\hat{\\beta}_{jk})$, where $z^*$ is calculated from the $N(0,1)$ distribution.\n\n-   We are $C\\%$ confident that for every one unit change in $x_{j}$, the odds of $y = k$ versus the baseline will multiply by a factor of $\\exp\\{\\hat{\\beta}_{jk} - z^* SE(\\hat{\\beta}_{jk})\\}$ to $\\exp\\{\\hat{\\beta}_{jk} + z^* SE(\\hat{\\beta}_{jk})\\}$, holding all else constant.\n\n## Interpreting CIs for $\\beta_{jk}$ {.smaller}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(health_fit, conf.int = TRUE) %>%\n  filter(y.level == \"Fair\") %>%\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|y.level |term          | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-------|:-------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|Fair    |(Intercept)   |    0.915|     0.164|     5.566|    0.00|    0.592|     1.237|\n|Fair    |Age           |    0.003|     0.003|     1.058|    0.29|   -0.003|     0.009|\n|Fair    |PhysActiveYes |   -1.645|     0.107|   -15.319|    0.00|   -1.856|    -1.435|\n:::\n:::\n\n<br>\n\n. . .\n\nWe are 95% confident, that for each additional year in age, the odds a person rates themselves as having fair health versus excellent health will multiply by 0.997 (exp(-0.003)) to 1.009 (exp(0.009)) , holding physical activity constant.\n\n## Interpreting CIs for $\\beta_{jk}$ {.smaller}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(health_fit, conf.int = TRUE) %>%\n  filter(y.level == \"Fair\") %>%\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|y.level |term          | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:-------|:-------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|Fair    |(Intercept)   |    0.915|     0.164|     5.566|    0.00|    0.592|     1.237|\n|Fair    |Age           |    0.003|     0.003|     1.058|    0.29|   -0.003|     0.009|\n|Fair    |PhysActiveYes |   -1.645|     0.107|   -15.319|    0.00|   -1.856|    -1.435|\n:::\n:::\n\n<br>\n\nWe are 95% confident that the odds a person who does physical activity will rate themselves as having fair health versus excellent health are 0.156 (exp(-1.856 )) to 0.238 (exp(-1.435)) times the odds for a person who doesn't do physical activity, holding age constant.\n\n## Recap\n\n-   Introduce multinomial logistic regression\n\n-   Interpret model coefficients\n\n-   Inference for a coefficient $\\beta_{jk}$",
    "supporting": [
      "lec-23_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}