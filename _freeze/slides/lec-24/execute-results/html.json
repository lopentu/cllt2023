{
  "hash": "ffc11cb284a2d5bb3534f459d7043348",
  "result": {
    "markdown": "---\ntitle: \"MultiLR: Prediction + inferential models\"\nsubtitle: \"STA 210 - Spring 2022\"\nauthor: \"Dr. Mine Çetinkaya-Rundel\"\nfooter: \"[sta210-s22.github.io/website](https://sta210-s22.github.io/website/)\"\nlogo: \"images/logo.png\"\nformat: \n  revealjs:\n    theme: slides.scss\n    transition: fade\n    slide-number: true\n    incremental: true \n    chalkboard: true\neditor: visual\nexecute:\n  freeze: auto\n  echo: true\n---\n\n\n\n# Welcome\n\n## Topics\n\n::: nonincremental\n-   Predictions\n-   Model selection\n-   Checking conditions\n:::\n\n## Computational setup\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# load packages\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(NHANES)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(colorblindr)\nlibrary(pROC)\nlibrary(Stat2Data)\nlibrary(nnet)\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 20))\n```\n:::\n\n## NHANES Data\n\n::: nonincremental\n-   [National Health and Nutrition Examination Survey](https://www.cdc.gov/nchs/nhanes/index.htm) is conducted by the National Center for Health Statistics (NCHS).\n-   The goal is to *\"assess the health and nutritional status of adults and children in the United States\".*\n-   This survey includes an interview and a physical examination.\n:::\n\n## Variables\n\n**Goal:** Use a person's age and whether they do regular physical activity to predict their self-reported health rating.\n\n-   Outcome: `HealthGen`: Self-reported rating of participant's health in general.\n    Excellent, Vgood, Good, Fair, or Poor.\n\n-   Predictors:\n\n    -   `Age`: Age at time of screening (in years). Participants 80 or older were recorded as 80.\n    -   `PhysActive`: Participant does moderate to vigorous-intensity sports, fitness or recreational activities.\n\n## The data\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnhanes_adult <- NHANES %>%\n  filter(Age >= 18) %>%\n  select(HealthGen, Age, PhysActive, Education) %>%\n  drop_na() %>%\n  mutate(obs_num = 1:n())\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglimpse(nhanes_adult)\n```\n\n::: {.cell-output-stdout}\n```\nRows: 6,465\nColumns: 5\n$ HealthGen  <fct> Good, Good, Good, Good, Vgood, Vgood, Vgood, Vgood, Vgood, …\n$ Age        <int> 34, 34, 34, 49, 45, 45, 45, 66, 58, 54, 50, 33, 60, 56, 56,…\n$ PhysActive <fct> No, No, No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, …\n$ Education  <fct> High School, High School, High School, Some College, Colleg…\n$ obs_num    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n```\n:::\n:::\n\n## Model in R\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhealth_fit <- multinom_reg() %>%\n  set_engine(\"nnet\") %>%\n  fit(HealthGen ~ Age + PhysActive, data = nhanes_adult)\n\nhealth_fit <- repair_call(health_fit, data = nhanes_adult)\n```\n:::\n\n## Model summary\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(health_fit) %>% print(n = 12)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 12 × 6\n   y.level term            estimate std.error statistic  p.value\n   <chr>   <chr>              <dbl>     <dbl>     <dbl>    <dbl>\n 1 Vgood   (Intercept)    1.27        0.154      8.23   1.80e-16\n 2 Vgood   Age           -0.0000361   0.00259   -0.0139 9.89e- 1\n 3 Vgood   PhysActiveYes -0.332       0.0949    -3.50   4.72e- 4\n 4 Good    (Intercept)    1.99        0.150     13.3    2.81e-40\n 5 Good    Age           -0.00304     0.00256   -1.19   2.35e- 1\n 6 Good    PhysActiveYes -1.01        0.0921   -11.0    4.80e-28\n 7 Fair    (Intercept)    1.03        0.174      5.94   2.89e- 9\n 8 Fair    Age            0.00113     0.00302    0.373  7.09e- 1\n 9 Fair    PhysActiveYes -1.66        0.109    -15.2    4.14e-52\n10 Poor    (Intercept)   -1.34        0.299     -4.47   7.65e- 6\n11 Poor    Age            0.0193      0.00505    3.83   1.30e- 4\n12 Poor    PhysActiveYes -2.67        0.236    -11.3    1.20e-29\n```\n:::\n:::\n\n# Predictions\n\n## Calculating probabilities {.smaller}\n\n-   For categories $2,\\ldots,K$, the probability that the $i^{th}$ observation is in the $j^{th}$ category is\n\n    $$\n    \\hat{\\pi}_{ij} = \\frac{e^{\\hat{\\beta}_{0j} + \\hat{\\beta}_{1j}x_{i1} + \\dots + \\hat{\\beta}_{pj}x_{ip}}}{1 + \\sum\\limits_{k=2}^K e^{\\hat{\\beta}_{0k} + \\hat{\\beta}_{1k}x_{i1} + \\dots \\hat{\\beta}_{pk}x_{ip}}}\n    $$\n\n-   For the baseline category, $k=1$, we calculate the probability $\\hat{\\pi}_{i1}$ as\n\n    $$\n    \\hat{\\pi}_{i1} = 1- \\sum\\limits_{k=2}^K \\hat{\\pi}_{ik}\n    $$\n\n## Predicted health rating {.smaller}\n\nWe can use our model to predict a person's perceived health rating given their age and whether they exercise.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhealth_aug <- augment(health_fit, new_data = nhanes_adult)\nhealth_aug\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 6,465 × 11\n   HealthGen   Age PhysActive Education      obs_num .pred_class .pred_Excellent\n   <fct>     <int> <fct>      <fct>            <int> <fct>                 <dbl>\n 1 Good         34 No         High School          1 Good                 0.0687\n 2 Good         34 No         High School          2 Good                 0.0687\n 3 Good         34 No         High School          3 Good                 0.0687\n 4 Good         49 No         Some College         4 Good                 0.0691\n 5 Vgood        45 Yes        College Grad         5 Vgood                0.155 \n 6 Vgood        45 Yes        College Grad         6 Vgood                0.155 \n 7 Vgood        45 Yes        College Grad         7 Vgood                0.155 \n 8 Vgood        66 Yes        Some College         8 Vgood                0.157 \n 9 Vgood        58 Yes        College Grad         9 Vgood                0.156 \n10 Fair         54 Yes        9 - 11th Grade      10 Vgood                0.156 \n# … with 6,455 more rows, and 4 more variables: .pred_Vgood <dbl>,\n#   .pred_Good <dbl>, .pred_Fair <dbl>, .pred_Poor <dbl>\n```\n:::\n:::\n\n## Actual vs. predicted health rating\n\nFor each observation, the predicted perceived health rating is the category with the highest predicted probability.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhealth_aug %>% select(contains(\"pred\"))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 6,465 × 6\n   .pred_class .pred_Excellent .pred_Vgood .pred_Good .pred_Fair .pred_Poor\n   <fct>                 <dbl>       <dbl>      <dbl>      <dbl>      <dbl>\n 1 Good                 0.0687       0.243      0.453     0.201     0.0348 \n 2 Good                 0.0687       0.243      0.453     0.201     0.0348 \n 3 Good                 0.0687       0.243      0.453     0.201     0.0348 \n 4 Good                 0.0691       0.244      0.435     0.205     0.0467 \n 5 Vgood                0.155        0.393      0.359     0.0868    0.00671\n 6 Vgood                0.155        0.393      0.359     0.0868    0.00671\n 7 Vgood                0.155        0.393      0.359     0.0868    0.00671\n 8 Vgood                0.157        0.400      0.342     0.0904    0.0102 \n 9 Vgood                0.156        0.397      0.349     0.0890    0.00872\n10 Vgood                0.156        0.396      0.352     0.0883    0.00804\n# … with 6,455 more rows\n```\n:::\n:::\n\n## Confusion matrix\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhealth_conf <- health_aug %>% \n  count(HealthGen, .pred_class, .drop = FALSE) %>%\n  pivot_wider(names_from = .pred_class, values_from = n)\n\nhealth_conf\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 5 × 6\n  HealthGen Excellent Vgood  Good  Fair  Poor\n  <fct>         <int> <int> <int> <int> <int>\n1 Excellent         0   528   210     0     0\n2 Vgood             0  1341   743     0     0\n3 Good              0  1226  1316     0     0\n4 Fair              0   296   625     0     0\n5 Poor              0    24   156     0     0\n```\n:::\n:::\n\n## Actual vs. predicted health rating\n\n::: question\nWhy do you think no observations were predicted to have a rating of \"Excellent\", \"Fair\", or \"Poor\"?\n:::\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n::: {.cell-output-display}\n![](lec-24_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='center' width=100%}\n:::\n\n::: {.cell-output-display}\n![](lec-24_files/figure-revealjs/unnamed-chunk-10-2.png){fig-align='center' width=100%}\n:::\n:::\n\n# Model selection for inference\n\n## Comparing nested models {.smaller}\n\n-   Suppose there are two models:\n    -   Reduced model includes predictors $x_1, \\ldots, x_q$\n    -   Full model includes predictors $x_1, \\ldots, x_q, x_{q+1}, \\ldots, x_p$\n-   We want to test the following hypotheses:\n    -   $H_0: \\beta_{q+1} = \\dots = \\beta_p = 0$\n    -   $H_A: \\text{ at least 1 }\\beta_j \\text{ is not } 0$\n-   To do so, we will use the **drop-in-deviance test** (very similar to logistic regression)\n\n## Add `Education` to the model? {.smaller}\n\n-   We consider adding the participants' `Education` level to the model.\n    -   Education takes values `8thGrade`, `9-11thGrade`, `HighSchool`, `SomeCollege`, and `CollegeGrad`\n-   Models we're testing:\n    -   Reduced model: `Age`, `PhysActive`\n    -   Full model: `Age`, `PhysActive`, `Education`\n\n. . .\n\n$$\n\\begin{align}\n&H_0: \\beta_{9-11thGrade} = \\beta_{HighSchool} = \\beta_{SomeCollege} = \\beta_{CollegeGrad} = 0\\\\\n&H_a: \\text{ at least one }\\beta_j \\text{ is not equal to }0\n\\end{align}\n$$\n\n## Add `Education` to the model?\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nreduced_fit <- multinom_reg() %>%\n  set_engine(\"nnet\") %>%\n  fit(HealthGen ~ Age + PhysActive,\n  data = nhanes_adult)\n\nfull_fit <- multinom_reg() %>%\n  set_engine(\"nnet\") %>%\n  fit(HealthGen ~ Age + PhysActive + Education,\n  data = nhanes_adult)\n  \nreduced_fit <- repair_call(reduced_fit, data = nhanes_adult)\nfull_fit <- repair_call(full_fit, data = nhanes_adult)\n```\n:::\n\n## Add `Education` to the model? {.smaller}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nanova(reduced_fit$fit, full_fit$fit, test = \"Chisq\") %>%\n  kable(digits = 3)\n```\n\n::: {.cell-output-display}\n|Model                        | Resid. df| Resid. Dev|Test   |    Df| LR stat.| Pr(Chi)|\n|:----------------------------|---------:|----------:|:------|-----:|--------:|-------:|\n|Age + PhysActive             |     25848|   16994.23|       |    NA|       NA|      NA|\n|Age + PhysActive + Education |     25832|   16505.10|1 vs 2 |    16|  489.132|       0|\n:::\n:::\n\n. . .\n\nAt least one coefficient associated with `Education` is non-zero.\nTherefore, we will include `Education` in the model.\n\n## Model with `Education` {.smaller}\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(full_fit, conf.int = T) %>% print(n = 28)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 28 × 8\n   y.level term         estimate std.error statistic  p.value conf.low conf.high\n   <chr>   <chr>           <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n 1 Vgood   (Intercept)   5.82e-1   0.301      1.93   5.36e- 2 -0.00914   1.17   \n 2 Vgood   Age           1.12e-3   0.00266    0.419  6.75e- 1 -0.00411   0.00634\n 3 Vgood   PhysActiveY… -2.64e-1   0.0985    -2.68   7.33e- 3 -0.457    -0.0711 \n 4 Vgood   Education9 …  7.68e-1   0.308      2.49   1.27e- 2  0.164     1.37   \n 5 Vgood   EducationHi…  7.01e-1   0.280      2.51   1.21e- 2  0.153     1.25   \n 6 Vgood   EducationSo…  7.88e-1   0.271      2.90   3.71e- 3  0.256     1.32   \n 7 Vgood   EducationCo…  4.08e-1   0.268      1.52   1.28e- 1 -0.117     0.933  \n 8 Good    (Intercept)   2.04e+0   0.272      7.51   5.77e-14  1.51      2.57   \n 9 Good    Age          -1.72e-3   0.00263   -0.651  5.15e- 1 -0.00688   0.00345\n10 Good    PhysActiveY… -7.58e-1   0.0961    -7.88   3.16e-15 -0.946    -0.569  \n11 Good    Education9 …  3.60e-1   0.275      1.31   1.90e- 1 -0.179     0.899  \n12 Good    EducationHi…  8.52e-2   0.247      0.345  7.30e- 1 -0.399     0.569  \n13 Good    EducationSo… -1.13e-2   0.239     -0.0472 9.62e- 1 -0.480     0.457  \n14 Good    EducationCo… -8.91e-1   0.236     -3.77   1.65e- 4 -1.35     -0.427  \n15 Fair    (Intercept)   2.12e+0   0.288      7.35   1.91e-13  1.55      2.68   \n16 Fair    Age           3.35e-4   0.00312    0.107  9.14e- 1 -0.00578   0.00645\n17 Fair    PhysActiveY… -1.19e+0   0.115    -10.4    3.50e-25 -1.42     -0.966  \n18 Fair    Education9 … -2.24e-1   0.279     -0.802  4.22e- 1 -0.771     0.323  \n19 Fair    EducationHi… -8.32e-1   0.252     -3.31   9.44e- 4 -1.33     -0.339  \n20 Fair    EducationSo… -1.34e+0   0.246     -5.46   4.71e- 8 -1.82     -0.861  \n21 Fair    EducationCo… -2.51e+0   0.253     -9.91   3.67e-23 -3.00     -2.01   \n22 Poor    (Intercept)  -2.00e-1   0.411     -0.488  6.26e- 1 -1.01      0.605  \n23 Poor    Age           1.79e-2   0.00509    3.53   4.21e- 4  0.00797   0.0279 \n24 Poor    PhysActiveY… -2.27e+0   0.242     -9.38   6.81e-21 -2.74     -1.79   \n25 Poor    Education9 … -3.60e-1   0.353     -1.02   3.08e- 1 -1.05      0.332  \n26 Poor    EducationHi… -1.15e+0   0.334     -3.44   5.86e- 4 -1.81     -0.494  \n27 Poor    EducationSo… -1.07e+0   0.316     -3.40   6.77e- 4 -1.69     -0.454  \n28 Poor    EducationCo… -2.32e+0   0.366     -6.34   2.27e-10 -3.04     -1.60   \n```\n:::\n:::\n\n## Compare NHANES models using AIC\n\nReduced model:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglance(reduced_fit)$AIC\n```\n\n::: {.cell-output-stdout}\n```\n[1] 17018.23\n```\n:::\n:::\n\n. . .\n\nFull model:\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nglance(full_fit)$AIC\n```\n\n::: {.cell-output-stdout}\n```\n[1] 16561.1\n```\n:::\n:::\n\n# Checking conditions for inference\n\n## Conditions for inference\n\nWe want to check the following conditions for inference for the multinomial logistic regression model:\n\n1.  Linearity: Is there a linear relationship between the log-odds and the predictor variables?\n\n2.  Randomness: Was the sample randomly selected?\n    Or can we reasonably treat it as random?\n\n3.  Independence: Are the observations independent?\n\n## Checking linearity\n\nSimilar to logistic regression, we will check linearity by examining empirical logit plots between each level of the response and the quantitative predictor variables.\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnhanes_adult <- nhanes_adult %>%\n  mutate(\n    Excellent = factor(if_else(HealthGen == \"Excellent\", \"1\", \"0\")),\n    Vgood = factor(if_else(HealthGen == \"Vgood\", \"1\", \"0\")),\n    Good = factor(if_else(HealthGen == \"Good\", \"1\", \"0\")),\n    Fair = factor(if_else(HealthGen == \"Fair\", \"1\", \"0\")),\n    Poor = factor(if_else(HealthGen == \"Poor\", \"1\", \"0\"))\n  )\n```\n:::\n\n## Checking linearity\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n\n```{.r .cell-code}\nemplogitplot1(Excellent ~ Age, data = nhanes_adult, \n              ngroups = 10, main = \"Excellent vs. Age\")\n```\n\n::: {.cell-output-display}\n![](lec-24_files/figure-revealjs/unnamed-chunk-17-1.png){fig-align='center' width=90%}\n:::\n\n```{.r .cell-code}\nemplogitplot1(Vgood ~ Age, data = nhanes_adult, \n              ngroups = 10, main = \"Vgood vs. Age\")\n```\n\n::: {.cell-output-display}\n![](lec-24_files/figure-revealjs/unnamed-chunk-17-2.png){fig-align='center' width=90%}\n:::\n:::\n\n## Checking linearity\n\n::: {.cell layout-ncol=\"2\" layout-align=\"center\"}\n\n```{.r .cell-code}\nemplogitplot1(Good ~ Age, data = nhanes_adult, \n              ngroups = 10, main = \"Good vs. Age\")\n```\n\n::: {.cell-output-display}\n![](lec-24_files/figure-revealjs/unnamed-chunk-18-1.png){fig-align='center' width=100%}\n:::\n\n```{.r .cell-code}\nemplogitplot1(Fair ~ Age, data = nhanes_adult, \n              ngroups = 10, main = \"Fair vs. Age\")\n```\n\n::: {.cell-output-display}\n![](lec-24_files/figure-revealjs/unnamed-chunk-18-2.png){fig-align='center' width=100%}\n:::\n:::\n\n## Checking linearity\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nemplogitplot1(Poor ~ Age, data = nhanes_adult, \n              ngroups = 10, main = \"Poor vs. Age\")\n```\n\n::: {.cell-output-display}\n![](lec-24_files/figure-revealjs/unnamed-chunk-19-1.png){fig-align='center' width=90%}\n:::\n:::\n\n. . .\n\n✅ The linearity condition is satisfied.\nThere is a linear relationship between the empirical logit and the quantitative predictor variable, Age.\n\n## Checking randomness\n\nWe can check the randomness condition based on the context of the data and how the observations were collected.\n\n-   Was the sample randomly selected?\n\n-   If the sample was not randomly selected, ask whether there is reason to believe the observations in the sample differ systematically from the population of interest.\n\n. . .\n\n✅ The randomness condition is satisfied.\nWe do not have reason to believe that the participants in this study differ systematically from adults in the U.S..\n\n## Checking independence\n\nWe can check the independence condition based on the context of the data and how the observations were collected.\n\nIndependence is most often violated if the data were collected over time or there is a strong spatial relationship between the observations.\n\n. . .\n\n✅ The independence condition is satisfied.\nIt is reasonable to conclude that the participants' health and behavior characteristics are independent of one another.\n\n## Recap\n\n-   Predictions\n-   Model selection for inference\n-   Checking conditions for inference",
    "supporting": [
      "lec-24_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}