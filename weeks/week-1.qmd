---
title: "Week1 Orientation"
author: "è¬èˆ’å‡± å°å¤§èªè¨€æ‰€"
format: 
    revealjs:
      slide-number: true
      preview-links: auto
      chalkboard: true
      logo: ../images/logo_round.png
    html:
        code-fold: true
bibliography: ../cllt.bib
---

# æ­¡è¿åŠ å…¥èªè¨€èˆ‡è³‡è¨Šçš„ä¸–ç•Œ

![](../images/me.png)


<!-- ---
æ¸¬è©¦ -->

# è¨ˆç®—èªè¨€å­¸èˆ‡èªè¨€å­¸ç†è«–

- è¨ˆç®—èªè¨€å­¸
    
- èªè¨€å­¸ç†è«–

- å®ƒå€‘ä¹‹é–“çš„é—œä¿‚
    - CL4LT
    - LT4CL
    - CLwithLT

::: aside
è¨ˆç®—èªè¨€å­¸æ˜¯è‹±æ–‡çš„ç›´è­¯ã€‚åœ¨æ­æ´²å‚³çµ±ä¸Šå«åšèªè¨€è³‡è¨Šå­¸ (linguistique informatique)ï¼Œæˆ–é›»è…¦èªè¨€å­¸ (Computerlinguistik)ï¼Œå¯èƒ½æ›´çˆ²å‚³ç¥ã€‚
:::


# è¨ˆç®—èªè¨€å­¸å’Œè‡ªç„¶èªè¨€è™•ç†

::: {.panel-tabset}

### è¨ˆç®—èªè¨€å­¸

- æ˜¯ä¸€é–€èªè¨€å­¸çš„å­é ˜åŸŸã€‚åˆ©ç”¨é›»è…¦ç•¶æˆç ”ç©¶è¼”åŠ©å·¥å…·ï¼Œæ¢ç©¶èªè¨€çš„çµæ§‹ã€æ¼”åŒ–ã€è®Šç•°ã€å­¸ç¿’ç­‰å•é¡Œã€‚ 

### è‡ªç„¶èªè¨€è™•ç†ï¼ˆNatural Language Processing, NLPï¼‰

- ç›®çš„æ˜¯ AI å°å‘ï¼Œè®“æ©Ÿå™¨èƒ½å¤ ç†è§£äººé¡çš„èªè¨€ï¼Œä¸¦ä¸”èƒ½å¤ é€éèªè¨€ä¾†èˆ‡äººé¡æºé€šã€‚
    
    - è‡ªç„¶èªè¨€è™•ç† | Natural Language Processing
    - è‡ªç„¶èªè¨€ç†è§£ | Natural Language Understanding
    - è‡ªç„¶èªè¨€ç”Ÿæˆ | Natural Language Generation

:::



## è‡ªç„¶èªè¨€è™•ç† 

- ç ”ç©¶æ…£ä¾‹ä¸Šï¼Œå°‡èªè¨€è³‡è¨Šçš„å•é¡Œåˆ‡åˆ†æˆä¸åŒçš„å­**[ä»»å‹™](http://nlpprogress.com/)**ï¼Œæˆç†Ÿä¹‹å¾Œå°±è®Šæˆå¤§å®¶è¼ƒç†Ÿæ‚‰çš„**æ‡‰ç”¨**ã€‚

    - èªéŸ³è¾¨è­˜èˆ‡èªéŸ³åˆæˆ
    - æ–‡æœ¬æ‘˜è¦
    - æ©Ÿå™¨ç¿»è­¯
    - è‡ªå‹•å•ç­”
    - ã€‚ã€‚ã€‚ã€‚


::: aside
æ›¾ç¶“èªéŸ³èˆ‡å¤šæ¨¡æ…‹(multimodality)æ˜¯æ¯”è¼ƒä¸æ­¸é¡åœ¨ NLP çš„é ˜åŸŸï¼Œä½†æœ€è¿‘å¹¾å¹´çš„é€²å±•èˆ‡è¶¨å‹¢ï¼Œä¹Ÿèˆ‡ NLP çš„ç ”ç©¶ç¤¾ç¾¤å¯†åˆ‡äº’å‹•ã€‚
:::

    




## è¨ˆç®—èªè¨€å­¸ 

:::{.incremental}

- æ¼¢èªçš„é›™éŸ³ç¯€åŒ–æ˜¯æ€éº¼æ¼”åŒ–çš„ ï¼ˆcomputational historical linguisticsï¼‰

- æ–°è© (neologism)ã€æ–°æ§‹å¼ (constructions) æ˜¯æ€éº¼åœ¨ç¤¾ç¾¤ä¸­çªç¾ã€å‚³éã€æ¶ˆäº¡çš„ ï¼ˆcomputational sociolinguisticsï¼‰

- é¢å°å®Œå…¨æ²’æœ‰æ¥è§¸éçš„èªè¨€ï¼Œå¦‚ä½•ç†è§£èˆ‡ç·¨å¯«èªæ³•ç³»çµ±ï¼Ÿï¼ˆcomputational linguistic typology/ xenolinguisticsï¼‰

- ....... (ä½ çš„æƒ³æ³•ï¼Ÿ)
:::





## å¾èªè¨€çš„è™•ç†åˆ°ç†è§£
From Natural Language <font color='blue'>Processing</font> to National Language <font color='red'>Understanding</font>

- å°æ–¼è™•ç†èˆ‡ç†è§£ï¼Œéƒ½æ˜¯**æ“ä½œå‹å®šç¾©** (operationalized)ã€‚


## å‚³çµ±è‡ªç„¶èªè¨€è™•ç†çš„ç™¼å±•


![](../images/pipe.png)


::: aside
[ä¸­æ–‡ AI çŸ¥è­˜åº«èˆ‡è‡ªç„¶èªè¨€è™•ç†æ ¸å¿ƒå¥—ä»¶ç ”è¨æœƒ](https://lope.linguistics.ntu.edu.tw/ioltw/linghacks21/AI_coreNLP_workshop/)
:::



## (å€‹äººè§€é»)

:::{.incremental}

- (å½¢å¼)èªè¨€å­¸èˆ‡å‚³çµ±è‡ªç„¶èªè¨€è™•ç†ä¸­çš„ [Modularity](https://www.wikiwand.com/en/Language_module) é è¨­ï¼Œ
æ˜¯å¥½ç”¨çš„è™›æ§‹ (useful fiction, Haugen and Dil, 1972)ï¼Œæ–¹ä¾¿æ•´ç†çŸ¥è­˜ï¼Œä½†éçœŸå¯¦çš„èªè¨€ç¾è±¡ã€‚

- èªè¨€ï¼šäººé¡ï¼Œçˆ²äº†æºé€šç›®çš„ï¼Œåœ¨æ™‚ç©ºè„ˆçµ¡ä¸‹ï¼Œç™¼å±•å‡ºçš„å½¢æ„ç¬¦è™Ÿç³»çµ±ã€‚
(cultural Species; form-meaning pairing; symbolic; self-adaptive complex system; situated and embodied cognition; etc.)

- ç¬¦ç¢¼æœ¬è³ªæ˜¯å½¢æ„æ˜ å°„ï¼Œè€ŒæŒ‡æ¶‰æ„ç¾©æ˜¯ç´„å®šä¿—æˆã€å¾ˆåƒæƒ…å¢ƒçš„ã€‚å› æ­¤ç¬¦ç¢¼é‹ç®—èˆ‡è¡¨å¾µæ˜¯çµ¦äººçœ‹çš„ã€‚èªè¨€çš„ç†è§£ï¼Œæ¶‰åŠåˆ°æ›´è¤‡é›œçš„**é€£çºŒçš„éç¨‹**ï¼Œè€Œéä¸€å€‹**åˆ†æ®µã€åˆ†è§£çš„éç¨‹**ã€‚  

- èªè¨€å­¸ä¸ç­‰æ–¼ rule-basedã€‚







:::



## å¤§å‹é è¨“ç·´èªè¨€æ¨¡å‹
pre-trained Large Language Models (pre-LLMs)

- æ”¹è®Šäº†(ç›®å‰)çš„è‡ªç„¶èªè¨€è™•ç†ç ”ç©¶æ–¹å‘


## GPT-3 and Beyond
å¾ˆæ¸…æ¥šçš„ç§‘æ™®ä»‹ç´¹

{{< video https://youtu.be/-lnHHWRCDGk >}}






## post-AI NLP: in-context learning (prompt-training)

a new paradigm of NLP that is based on the recent advances in AI, especially in the field of language modeling.


> Recently, we have seen dramatic advances in natural language processing (NLP) driven by huge pre-trained language models such as GPT-3 and DALLE-2. Instead of building many small task-specific models, there is a movement to create and use these more all-purpose huge language models for many NLP applications. 

The most intriguing finding is that these models employ a new learning paradigm:Â in-context learning, where they learn to do a downstream task simply by conditioning on a prompt consisting of a few input-output examples without any parameter updates 






## å¦‚ä½•å½±éŸ¿æ•™å­¸
(é †ä¾¿ä»‹ç´¹åŠ©æ•™ç¾¤ ğŸ˜„)

![](../images/chatGPT.png)





## çˆ²ä»€éº¼æˆ‘å€‘å¯ä»¥æ”¾å¿ƒï¼ˆæˆ–æ‡‰è©²æ“”å¿ƒï¼‰ï¼Ÿ
aka. ç„¡ä¸­ç”Ÿæœ‰ï¼Œè·ŸçœŸçš„ä¸€æ¨£


![](../images/potts.png)


![](../images/sk.jpg)







# é€™é–€èª²çš„å­¸ç¿’æ–¹å‘èˆ‡æ…‹åº¦

:::{.incremental}

- AI-aside, treated as IA (intelligent assistant) with sophisticated prompt-training; (ä¸è¦è¢«å®ƒæ˜¯å¦æ˜¯ GAI çš„å•é¡Œç³¾çµï¼Œé‚„ä¸æ˜¯ï¼)

- ä¸è¦å›¿é™æ–¼è‡ªå·±çš„é ˜åŸŸè§€é»ï¼ˆå·¥ç¨‹æˆ–äººæ–‡ï¼‰ï¼Œæˆ–è‡ªå·±çš„ç”Ÿå‘½å½¢æ…‹ï¼ˆç¢³åŸºï¼‰ã€‚

    > åœ¨ç ”ç©¶ä¸­ï¼Œæˆ‘å€‘æœƒé‡åˆ°å¾ˆå¤šä¸åŒçš„è§€é»ï¼Œç”šè‡³æ˜¯ä¸åŒçš„é ˜åŸŸã€‚æˆ‘å€‘è¦å­¸æœƒå¦‚ä½•å»ç†è§£ä¸åŒçš„è§€é»ï¼Œä¸¦ä¸”èƒ½å¤ åœ¨ä¸åŒçš„é ˜åŸŸä¸­è‡ªå¦‚åœ°ç§»å‹•ã€‚(AI, 2023)
:::


---

![](../images/time.png)




æˆ‘å€‘ç†è§£ã€Œæ™‚é–“ã€çš„æ–¹å¼ä¸åŒï¼Œå½¼æ­¤å°Šé‡ã€‚



## æˆ‘å€‘æ€éº¼å¯¦ä½œé€™é–€èª²ï¼Ÿ

- æˆ‘å€‘çš„ä¸»è¦å­¸ç¿’é‡é»ä¸æœƒæ”¾åœ¨è‡ªç„¶èªè¨€è™•ç†ä¸­çš„**æ©Ÿå™¨å­¸ç¿’æ¨¡å‹åŸç†** (è«‹å¤§å®¶åœ¨å…¶ä»–çš„èª²ç¨‹ä¸­ä¸¦è¡Œå­¸ç¿’)ï¼Œè€Œæ˜¯æ”¾åœ¨**èªè¨€å­¸ç†è«–èˆ‡è‡ªç„¶èªè¨€è™•ç†çš„é—œä¿‚**ã€‚

- é¸æ“‡æœ‰èªè¨€å­¸èƒŒæ™¯çš„æ•™æ (å¦‚ Jurafsky & Martin SLP3, Christopher Potts cs224u, etc.) ä¾†é€²è¡Œèª²ç¨‹çš„æ•™å­¸ï¼Œä¸¦è£œå……ä¸åŒçš„è§€é»ã€‚

::: {.callout-warning}
é€™æ˜¯*æ²’æœ‰*æ•™ç§‘æ›¸çš„å­¸é–€
:::

- å¯¦ä½œéƒ¨åˆ†å´é‡æ‡‰ç”¨ã€‚


## çœ‹çœ‹ç•¶å‰çš„ç ”ç©¶æ•™å­¸

[Introduction and course overview](https://web.stanford.edu/class/cs224u/slides/cs224u-intro-handout.pdf)